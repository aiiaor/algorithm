{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkH7tzLdbmAs"
      },
      "source": [
        "k-Core Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6M05k7AbuVA"
      },
      "source": [
        "For more information about the project, please refer to the [project specification](https://cgi.cse.unsw.edu.au/~cs9312/24T2/project/). You can edit this file and add anything you like. We will only use the code cell of the `KCore` class for testing. You can add descriptions and some theoretical analysis (e.g. index space, query time complexity, and index time complexity) to this file without creating a separate PDF document.\n",
        "\n",
        "**Note**: Make sure to **sequentially run all cells in each section** in order to carry over intermediate variables/packages to the next cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOKtK2jtCwLD"
      },
      "source": [
        "## 1. Code Template\n",
        "You need to implement the `KCore` class to support k-core queries for large graphs (e.g. hundreds of millions of vertices and edges). A code template is given below.\n",
        "\n",
        "The `KCore` class is initialized by a graph `G`. The data structure of `G` will be presented in the next section. The class calls the function `preprocess` to precompute some index structure for `G`. The `query` function has one inputs: `k`. The function outputs the `k`-cores in `G`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fv9lxWkJblNE"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# You can import any Python Standard Library modules~\n",
        "from collections import deque\n",
        "import networkx as nx\n",
        "################################################################################\n",
        "\n",
        "class KCore(object):\n",
        "    def __init__(self, G):\n",
        "\n",
        "        self.vertex_num = G.vertex_num\n",
        "        self.adj_list = G.adj_list\n",
        "        self.d = [len(G.adj_list[u]) for u in range(self.vertex_num)]\n",
        "\n",
        "        self.D = sorted(range(len(self.d)), key=lambda k: self.d[k])\n",
        "\n",
        "        self.p = [0]*G.vertex_num\n",
        "        for i in range(G.vertex_num):\n",
        "            self.p[self.D[i]] = i\n",
        "\n",
        "        self.b = {}\n",
        "        bucket_val = 1\n",
        "        index = 0\n",
        "        while index < G.vertex_num:\n",
        "            if bucket_val == self.d[self.D[index]]:\n",
        "                self.b[bucket_val] = index\n",
        "                index = index + 1\n",
        "                bucket_val = bucket_val + 1\n",
        "            elif bucket_val < self.d[self.D[index]]:\n",
        "                while bucket_val < self.d[self.D[index]]:\n",
        "                    bucket_val = bucket_val + 1\n",
        "            elif bucket_val > self.d[self.D[index]]:\n",
        "                index = index + 1\n",
        "\n",
        "        self.preprocess(G)\n",
        "\n",
        "    def preprocess(self, G):\n",
        "        for i in range(self.vertex_num):\n",
        "            v=self.D[i]\n",
        "            for u in self.adj_list[v]:\n",
        "                if self.d[u]>self.d[v]:\n",
        "                    du = self.d[u]\n",
        "                    pu = self.p[u]\n",
        "                    if du not in self.b:\n",
        "                        flag = 1\n",
        "                        for k in self.b:\n",
        "                            if du < k:\n",
        "                                self.b[du] = self.b[k]\n",
        "                                flag = 0\n",
        "                                break\n",
        "                        if flag:\n",
        "                            self.b[du] = self.vertex_num-1\n",
        "                    pw = self.b[du]\n",
        "                    w = self.D[pw]\n",
        "\n",
        "                    if u!=w:\n",
        "                        self.p[u] = pw\n",
        "                        self.p[w] = pu\n",
        "                        self.D[pu] = w\n",
        "                        self.D[pw] = u\n",
        "                    self.b[du] += 1\n",
        "                    if self.b[du] >= self.vertex_num:\n",
        "                        self.b.pop(du)\n",
        "                    self.d[u] -= 1\n",
        "       \n",
        "        return self.d\n",
        "\n",
        "    def query(self, k):\n",
        "        cores = []\n",
        "        unvisited = [0]*self.vertex_num\n",
        "        loc_unvisited = [0]*self.vertex_num\n",
        "        unvisited_len = self.vertex_num - 1\n",
        "        for i in range(self.vertex_num):\n",
        "            unvisited[i] = i\n",
        "            loc_unvisited[i] = i\n",
        "        \n",
        "        while unvisited_len > 0:\n",
        "            v = unvisited[unvisited_len]\n",
        "\n",
        "            if self.d[v] < k:\n",
        "                unvisited_len -= 1\n",
        "                continue\n",
        "            \n",
        "            group = []\n",
        "            q = deque()\n",
        "            q.append(v)\n",
        "            while len(q) > 0:\n",
        "                u = q.popleft()\n",
        "                if (loc_unvisited[u] > unvisited_len) or (self.d[u] < k):\n",
        "                    continue\n",
        "\n",
        "                group.append(u)\n",
        "                unvisited,loc_unvisited = self.swap(unvisited,loc_unvisited,loc_unvisited[u],unvisited_len)\n",
        "\n",
        "                unvisited_len -= 1\n",
        "                for w in self.adj_list[u]:\n",
        "                    if (self.d[w] >= k) and (loc_unvisited[w] <= unvisited_len):\n",
        " \n",
        "                        q.append(w)\n",
        "                    elif (self.d[w] < k) and (loc_unvisited[w] <= unvisited_len):\n",
        "\n",
        "                        unvisited,loc_unvisited = self.swap(unvisited,loc_unvisited,loc_unvisited[w],unvisited_len)\n",
        "                        unvisited_len -= 1\n",
        "            cores.append(group)\n",
        "\n",
        "                    \n",
        "        return cores\n",
        "\n",
        "    def swap(self,arr,loc_arr, i, j):\n",
        "        temp = arr[i]\n",
        "        arr[i] = arr[j]\n",
        "        arr[j] = temp\n",
        "        loc_arr[arr[i]] = i\n",
        "        loc_arr[arr[j]] = j\n",
        "        return arr,loc_arr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htK1vOQaCSAm"
      },
      "source": [
        "## 2. Graph Data Structure\n",
        "The following is the data stucture of the input graph `G`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "De2hA58cCUQ0"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# Do not edit this code cell.\n",
        "################################################################################\n",
        "\n",
        "class UndirectedUnweightedGraph(object):\n",
        "    def __init__(self, edge_list):\n",
        "        self.adj_list = []\n",
        "        self.vertex_num = 0\n",
        "        self.edge_num = 0\n",
        "        info = True\n",
        "        for [vertex_u, vertex_v] in edge_list:\n",
        "            if info:\n",
        "                info = False\n",
        "                self.vertex_num = vertex_u\n",
        "                self.edge_num = vertex_v\n",
        "                self.adj_list = [list() for _ in range(self.vertex_num)]\n",
        "            else:\n",
        "                self.adj_list[vertex_u].append(vertex_v)\n",
        "                self.adj_list[vertex_v].append(vertex_u)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAqNxEF-Cef0"
      },
      "source": [
        "## 3. How to test your code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP3_0s2pChlN"
      },
      "source": [
        "### 3.1 Download the sample dataset.\n",
        "\n",
        "Running the following command will create the **COMP9312-24T2-Project** folder, which contains the files for the three datasets.\n",
        "\n",
        "> **Cora** (2k vertices) is a real citation graph, **map_BJ_part** (4k vertices) is a real road network for a small area of Beijing, and **map_NY_part** (7k vertices) is a real road network for a small area of New York. For the two road networks, we erase the weight of each edge in the original dataset to generate unweighted graphs for simplicity.\n",
        "\n",
        "There are three files for each dataset, where ***.graph** includes the graph information and all graph edges (vertex IDs are consecutive and start from 0), ***.query** includes a set of queries for testing. ***.answer** includes the correct answer to each query for your reference.\n",
        "\n",
        "If the dataset already exists, an error like \"*destination path 'COMP9312-24T2-Project' already exists*\" will appear.\n",
        "\n",
        "**NOTE**: We will test the code using different datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsPtpe_pClDF",
        "outputId": "a6a28370-d081-4645-9b57-8b5e6403cc29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'COMP9312-24T2-Project'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 15 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (15/15), 91.59 KiB | 4.16 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/kevinChnn/COMP9312-24T2-Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOk8bJw7CjEh"
      },
      "source": [
        "### 3.2 The main function\n",
        "\n",
        "Our test procedure first loads the graph dataset and the query dataset. Then, it calls the `KCore` class to preprocess the graph. After that, it will run each query and test its efficiency and correctness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L_83fbqCWfa",
        "outputId": "c49b6eb1-3968-48cf-af0a-1705bc712c94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "######## Loading the dataset...\n",
            "\n",
            "######## Preprocessing the graph...\n",
            "Preprocessing time: 0.00337720\n",
            "\n",
            "######## Query Testing...\n",
            "Querying 2-cores...\n",
            "Query time: 0.00338411 | 2-cores : True\n",
            "Querying 3-cores...\n",
            "Query time: 0.00156188 | 3-cores : True\n",
            "Querying 4-cores...\n",
            "Query time: 0.00058317 | 4-cores : True\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print('\\n######## Loading the dataset...')\n",
        "    #edge_list = np.loadtxt('./COMP9312-24T2-Project/test-kcore2.graph', dtype=int) \n",
        "    edge_list = np.loadtxt('./COMP9312-24T2-Project/cora.graph', dtype=int)\n",
        "    G = UndirectedUnweightedGraph(edge_list)\n",
        "    \n",
        "\n",
        "    print('\\n######## Preprocessing the graph...')\n",
        "    start_preprocessing = time.time()\n",
        "    KC = KCore(G)\n",
        "    end_preprocessing = time.time()\n",
        "    print(\"Preprocessing time: {:.8f}\".format(end_preprocessing-start_preprocessing))\n",
        "\n",
        "    print('\\n######## Query Testing...')\n",
        "    k_lo = 2 # inclusive\n",
        "    k_hi = 5 # exclusive\n",
        "    for k in range(k_lo,k_hi):\n",
        "        print(f\"Querying {k}-cores...\")\n",
        "        with open(f'./COMP9312-24T2-Project/cora-{k}.core', 'rb') as f:\n",
        "            correct_cores = pickle.load(f)\n",
        "        start_query = time.time()\n",
        "        cores = KC.query(k)\n",
        "        end_query = time.time()\n",
        "        \n",
        "        if len(cores) != len(correct_cores) or sum(len(core) for core in cores) != sum(len(core) for core in correct_cores):\n",
        "            print(\"Query time: {:.8f} | {}-cores : False\".format((end_query-start_query), k))\n",
        "        else:\n",
        "            test_cores = {frozenset(core) for core in cores}\n",
        "            print(\"Query time: {:.8f} | {}-cores : {}\".format((end_query-start_query), k, test_cores==correct_cores))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
